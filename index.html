<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Index</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>

		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-B6CGCXLZWE"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-B6CGCXLZWE');
		</script>

	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Intro -->
					<div id="intro">
						<!--
						<h2> Nadia Guerouaou </h2>
							Manipulating emotions in voice with algorithms, from ethics to therapy
						-->	
						<ul class="actions">
							<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Deep dive</a></li>
						</ul>
					</div>

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Nadia Guerouaou</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="active"><a href="index.html">Home</a></li>
							<li><a href="index.html#About">About</a></li>
							<li><a href="index.html#Teaching">Teaching</a></li>
							<li><a href="index.html#News">News</a></li>
							<li ><a href="index.html#Highlights"> Highlights</a></li>
							<li ><a href="publications.html">Publications</a></li>
							<li ><a href="talks.html">Talks</a></li>
							<li ><a href="GUEROUAOU_CV.pdf">CV</a></li>
							<li ><a href="teaching.html">Teaching</a></li>

						</ul>
						<ul class="icons">
							<li><a href="https://twitter.com/GuerouaouN" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="https://www.linkedin.com/in/nadia-guerouaou-004b28224/" class="icon brands fa-linkedin-in"><span class="label">Linked-in</span></a></li>
							<li><a href="https://github.com/nadiaguerouaou" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>					


				<!-- Main -->
					<div id="main">
						<!-- Intro -->
							<article class="post featured">
								<header class="major", id="About">
									<h3>About <br /></h3>
								</header>

								<div style=font-size:85%>
									<p><span class="image left"><img src="images/glitchhy_color_twit.png" alt="" /></span> I am a doctoral student in the <a href="https://www.https://www.stms-lab.fr/team/perception-et-design-sonores/">Perception and Sounds Design Team </a> (STMS lab/CNRS/Ircam Paris),  <a href="https://https://neuro-team-femto.github.io//"> NeuroTeam FEMTO </a> ((CNRS/Universit√© de Bourgogne Franche-Comt√©) and <a href="https://https://http://lilncog.eu/equipe-psy/"> Plasticity and Subjectivity Team </a> (Lille Neuroscience & Cognition Centre lab/INSERM/CHRU Lille). 

My doctoral research work focuses on algorithms able to manipulate and create emotions in the voice in real time aka Vocal Filters. 
My interest for this specific category of deepfakes is dual. On the one hand, I see it as a potential therapeutic tool, and on the other, like many tools, as an object of human enhancement.

<p> The therapeutic axis of this PhD focus on the voice of PTSD's patients. The first objective is to investigate new acoustic biomarkers in the patients' voice in order to better characterize both the pathology and the healing process associated with imaginative exposure psychotherapy. Ceci a pour objectif de is the use of voice transformation techniques developed at IRCAM puis at FEMTO for the purpose of augmented psychotherapy.  


<p> In parallel to my research activity, I have a degree in Neuropsychology and work as a clinical psychologist at the Regional Consultation of Psychotrauma in the Hauts de France, where I receive patients suffering from Post Traumatic Stress Disorder (PTSD).
									</p>
								</div>
								
							</article>
						<article class="post featured">
								<header class="major", id="Teaching">
									<h3>Teaching <br /></h3>
								</header>


							<div style=font-size:85%> Besides, I am also teaching Neuroethics, a discipline I teach Psychology and Neuropsychology students (Bachelor and Master) at Lille‚Äôs University. The core of these lectures mainly deal with the current and potential uses of new technologies emerging from research in cognitive neurosciences and the impact that misuses, particularly in the context of human augmentation, could have on our societies. These rapid technological advances, require continuous adaptation from users and experts, and open debates to overcome the techclash and bring out the essential questions for an enlightened use of these technologies.This interest is developed in my thesis work by the study of the acceptability of vocal deepfakes by the society, and in particular of expressive voice transformation technologies as well as the impact of culture on this acceptability (forthcoming study: comparison of the receptivity of vocal deepfakes between the French and Japanese populations).
								</p>
								</div>
							</div>
						<!-- Featured Post -->
							<article class="post featured">
									<h2 id="News">News</h2>
									<div class="table-wrapper" style='font-size:85%'>
										<table>
											<thead>
												<tr>
													<th>Date</th>
													<th>Description</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>Upcoming in 2023</td>
													<td text-align="justify"> We will release our new experimental platform DuckSoup in 2023 üóì. DuckSoup is an opensource videoconference platform allowing researchers to manipulate participants' facial and vocal attributes in real time during social interactions. If you are interested in collecting large, synchronised & multicultural human social interaction data sets get in touch! üßû‚Äç‚ôÇÔ∏è</td>
												</tr>

												<tr>
													<td>November 2022</td>
													<td text-align="justify"> We won the VR grant application from the Swedish Research Council to develop our new platform DuckSoup! 
													</td>
												</tr>

												<tr>
													<td>October 2022</td>
													<td text-align="justify">Starting my 2 months research stay on algorithmic transformations of emotions in voice (vocal filters) and their social acceptance in Japan at Pr Katsumi Watanabe‚Äôs Lab in.... Wish to meet researchers and artists interested by technology‚Äôs influence on society! üôè JSPS  Moving to Scotland to start a new position as Marie Curie Fellow in Glasgow University in the <a href="https://www.gla.ac.uk/schools/psychologyneuroscience/">School of Neuroscience and Psychology</a> department with <a href="https://scholar.google.co.uk/citations?user=cwgW51EAAAAJ&hl=en">Philippe Schyns</a> and <a href="https://scholar.google.co.uk/citations?user=gO2daQsAAAAJ&hl=en"> Rachael Jack</a>. Super psyched! ü§©
													</td>
												</tr>

												<tr>
													<td>June 2022</td>
													<td text-align="justify"> I won a Marie Curie postdoctoral fellowship for my proposal SINA (Studying Social Interactions with Audiovisual Transformations). In collaboration with Rachael Jack, Philippe Schyns (Glasgow University) and Petter Johansson (Lund Unviersity)! üí£</td>
												</tr>

												<tr>
													<td>June 2021</td>
													<td text-align="justify">We won the Sorbonne Univeristy "Emergence" call with our REVOLT (Revealing human bias with real time vocal deep fakes) proposal, in collaboration with Nicolas Obin (SU) üí•. </td>
												</tr>

												<tr>
													<td>Sept 2019</td>
													<td text-align="justify">I'm starting a new postdoctoral position at Lund University Cognitive Science in Sweden to work with Petter Johannsson and Lars Hall in the Choice Blindeness lab! We aim to create unprecedented methodological tools to study human social interaction mechanisms. </td>
												</tr>												

												<tr>
													<td>Dec 2018</td>
													<td text-align="justify">Defended my PhD thesis entitled <a href="https://hal.archives-ouvertes.fr/tel-02010161/file/PhD%20Arias.pdf"> The cognition of auditory smiles: a computational approach"</a>, which was evaluated by an inspring jury composed of <a href="https://scholar.google.fr/citations?user=XWdplJkAAAAJ&hl=en&oi=ao">Tecumseh Fitch</a> (Univ. Viena), <a href="https://scholar.google.fr/citations?user=XWdplJkAAAAJ&hl=en&oi=ao">Rachael Jack</a> (Univ. Glasgow), <a href="https://scholar.google.fr/citations?user=n9ZNrsEAAAAJ&hl=en&oi=ao">Catherine Pelachaud</a> (Sorbonne University), <a href="https://scholar.google.fr/citations?user=qKynVZ0AAAAJ&hl=en&oi=ao">Martine Gavaret</a>> (Paris Descartes),  <a href="https://scholar.google.fr/citations?user=PjXi-vYAAAAJ&hl=en&oi=ao">Julie Grezes</a>  and <a href="https://scholar.google.fr/citations?user=PjXi-vYAAAAJ&hl=en&oi=ao">Pascal Belin</a> (Univ. Aix Marseille), <a href="https://scholar.google.fr/citations?user=PjXi-vYAAAAJ&hl=en&oi=ao"> Patrick Susini</a> (IRCAM) and <a href="https://scholar.google.fr/citations?user=PjXi-vYAAAAJ&hl=en&oi=ao">Jean-Julien Aucouturier</a> (CNRS).</td>
												</tr>
											</tbody>
										</table>
									</div>
								
							</article>	

						<!-- Posts -->
							<section class="post">
								<header class="major", id="Highlights">
									<h2>Highlights </h2>
								</header>
							</section>								
							
							<section class="posts">
								
								<!-- Tokyo 2months research stay -->
								<article>
									<header>
										<span class="date">September-November, 2022</span>
										<h4><a href="https://neuro-team-femto.github.io/articles/2021/Arias_Current_Biology_2021.pdf">Tokyo 2months research stay<br /></a></h4>
									</header>

									<a href="https://neuro-team-femto.github.io/articles/2021/Arias_Current_Biology_2021.pdf" class="image fit"><img src="images/main_figure_CB_v1.jpg" alt="" /></a>

									<div style='font-size:85%'>
										<p> Two months JSPS fellowship in blablabla uviversity Tokyo. Funded to study the influence of culture in the judgment of moral acceptability of vocal filters in stakeholders. and the relationship researchers and artists  

										Check the full article <a href="https://neuro-team-femto.github.io/articles/2021/Arias_Current_Biology_2021.pdf">here</a>. Or check <a href="https://twitter.com/PabloAriasMusic/status/1453637734489284608">this</a> twitter thread explaining the findings.
										</p>
									</div>

								</article>

								<!-- Rendre sa voix plus souriante: deepfakes et filtres vocaux √©motionnels -->
								<article>
									<header>
										<span class="date">July, 2022</span>
										<h4><a href="https://aoc.media/analyse/2022/07/05/rendre-sa-voix-plus-souriante-deepfakes-et-filtres-vocaux-emotionnels/">Rendre sa voix plus souriante: deepfakes et filtres vocaux √©motionnels<br /></a></h4>
									</header>
									<a href="https://aoc.media/analyse/2022/07/05/rendre-sa-voix-plus-souriante-deepfakes-et-filtres-vocaux-emotionnels/" class="image fit"><img src="images/cover_aoc.jpeg" alt="" /></a>
									
										<div style='font-size:85%'>
											<p> We have a new article out in <i>AOC</i>! AOC is an authors' daily newspaper. Designed by journalists, it is written by researchers, writers, intellectuals, artists and... journalists. AOC intends to take a step back. To try to restore a little verticality to a now unstructured and horizontal public space by publishing texts that aim as much as possible to (re)establish authority and structure the debate.This specific format allowed me to propose a personal analysis both of the phenomenon and the results of our study published in Royal Society. I propose here to observe these emotional voice filters - which I consider to be the audio counterpart of the visual filters already widely used on social networks - as objects of anthropotechnics and the questions associated with this proposal. 
											</p>
										<div style='font-size:85%'>
								</article>

								<!-- L'√©tonnante acceptabilit√© des deepfakes -->
								<article>
									<header>
										<span class="date">January, 2022</span>
										<h4><a href="https://lejournal.cnrs.fr/billets/letonnante-acceptabilite-des-deep-fake">L'√©tonnante acceptabilit√© des deepfakes<br /></a></h4>
									</header>
									<a href="https://lejournal.cnrs.fr/billets/letonnante-acceptabilite-des-deep-fake" class="image fit"><img src="images/adobestock_Metamoworks.jpeg" alt="" /></a>
										<div style='font-size:85%'>
											<p>
											Our post on ‚ÄúThe surprising acceptability of deepfakes‚Äù has just been published in <a href="https://www.liberation.fr/idees-et-debats/tribunes/letonnante-acceptabilite-des-deep-fakes-20220106_E4MZA6GDJREARN25BBCA7JXH3M/">Lib√©ration</a>  & <a href="https://lejournal.cnrs.fr/billets/letonnante-acceptabilite-des-deep-fake">CNRS Le journal</a>. "Rapid improvements in deepfake technology, which modifies a person's appearance or voice in real time, call for an ethical review at this still early stage. Researchers in cognitive science shed some light on the public‚Äôs perception of this phenomenon." So slad we have been given the opportunity to talk about this topic of high societal interest üòÉ. Also available in english <a href="https://news.cnrs.fr/opinions/the-unforeseen-acceptance-of-deepfakes">here</a>.  
											</p>
										</div>
								</article>

								<!-- The shallow of your smile: the ethics of expressive vocal deep-fakes -->
								<article>
									<header>
										<span class="date">December, 2021</span>
										<h4><a href="https://doi.org/10.1098/rstb.2021.0083">The shallow of your smile: the ethics of expressive vocal deep-fakes.<br /></a></h4>
									</header>
									<a href="https://doi.org/10.1098/rstb.2021.0083" class="image fit"><img src="images/darwin.jpg" alt="" /></a>
										<div style='font-size:85%'>
											<p>
											Our article has been published in <i>Philosophical Transactions B of the Royal Society</i>! in just a few years, with the proliferation of ‚Äúdeep-fake‚Äù technologies, we‚Äôve come to a situation where it is difficult to trust whether the smiles, laughs and frowns of our conversation partners are genuine or algorithmically modulated. Inspired by the methodology of experimental ethics (autonomous vehicules...), we have conducted a study to evaluate the moral acceptability of 24 Black-mirroresque scenarios describing potential applications of vocal filters <a href="https://twitter.com/GuerouaouN/status/1469337128698093581?s=20&t=qIuGyYeG3LaGNQ5f2lqJ9Q">Here</a> the twitter thread explaining the study and findings.
											</p>
										</div>
								</article>
							</section>

					</div>


				<!-- Footer -->
					<!-- First Column -->
					<footer id="footer">
						<section class="split contact">
							<section>
								<h3>Email</h3>
								<p><a href="#">n[dot]guerouaou(At]gmail.com</a></p>
							</section>
						</section>

						<!-- Second Column -->
						<section class="split contact">
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="https://twitter.com/GuerouaouN" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="https://linkedin.com/in/nadia-guerouaou-004b28224" class="icon brands fa-linkedin-in"><span class="label">Linked-in</span></a></li>									
									<li><a href="https://github.com/nadiaguerouaou" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
